{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad015db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# URL da API Prometheus\n",
    "url = 'http://192.168.242.131:9090/api/v1/query?query=container_cpu_usage_seconds_total{pod=~\".*postgres.*\"}[10m]'\n",
    "\n",
    "# Fazendo a requisição GET\n",
    "response = requests.get(url)\n",
    "data = response.json()  # Converte a resposta para dict\n",
    "\n",
    "# Verifica se há resultados e estrutura esperada\n",
    "results = data.get('data', {}).get('result', [])\n",
    "\n",
    "# Lista para armazenar os registros\n",
    "records = []\n",
    "\n",
    "# Processa cada resultado\n",
    "for item in results:\n",
    "    # Extrai a série temporal (samples)\n",
    "    for value in item.get('values', []):\n",
    "        ts = float(value[0])  # Timestamp UNIX\n",
    "        cpu_val = float(value[1])\n",
    "        # Converte timestamp para Data/Hora legível\n",
    "        dt = datetime.utcfromtimestamp(ts)\n",
    "        \n",
    "        # Extrai o nome do pod dos labels\n",
    "        pod_name = item['metric'].get('pod', 'N/A')\n",
    "        records.append({\"timestamp\": dt, \"pod\": pod_name, \"cpu\": cpu_val})\n",
    "\n",
    "# Cria DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "#df = df.sort_values(by='timestamp', ascending=False)\n",
    "# Mostra resultado\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4df7a0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Iniciando consulta ao Prometheus com informações de Instance\n",
      "================================================================================\n",
      "\n",
      "🔍 Buscando pods PostgreSQL e suas instances...\n",
      "✅ Pods PostgreSQL encontrados:\n",
      "   📦 Pod: postgres-deployment-76d6f4778d-ccs8g\n",
      "      📍 Instance: x86\n",
      "      🔧 Container: postgres\n",
      "      📂 Namespace: stress-app\n",
      "\n",
      "\n",
      "✅ Usando pod: postgres-deployment-76d6f4778d-ccs8g\n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 Consultando memória do pod: postgres-deployment-76d6f4778d-ccs8g\n",
      "🌐 URL da consulta: http://192.168.242.131:9090/api/v1/query_range\n",
      "📋 Query: container_memory_usage_bytes{pod=\"postgres-deployment-76d6f4778d-ccs8g\", container!=\"POD\", container!=\"\"}\n",
      "⏰ Start: 1757245300 (2025-09-07 08:41:40)\n",
      "⏰ End: 1757247100 (2025-09-07 09:11:40)\n",
      "📊 Período: 30m\n",
      "📡 Fazendo requisição...\n",
      "📊 Status HTTP: 200\n",
      "✅ Encontrados 1 séries de dados\n",
      "\n",
      "🖥️  Instances encontradas:\n",
      "   📍 x86 (container: postgres)\n",
      "📦 Processando - Container: postgres, Instance: x86\n",
      "✅ Dataset criado com 61 registros\n",
      "\n",
      "================================================================================\n",
      "🖥️  RESUMO DAS INSTANCES\n",
      "================================================================================\n",
      "\n",
      "📍 Instance: x86\n",
      "   �� Container: postgres\n",
      "   🏷️  Pod: postgres-deployment-76d6f4778d-ccs8g\n",
      "   📂 Namespace: stress-app\n",
      "   🖥️  Node: N/A\n",
      "   📊 Memória - Min: 61.69 MB | Max: 65.96 MB | Média: 64.75 MB\n",
      "   📈 Registros: 61\n",
      "\n",
      "================================================================================\n",
      "📊 DATASET COMPLETO\n",
      "================================================================================\n",
      "📈 Total de registros: 61\n",
      "⏰ Período: 2025-09-07 11:41:40 até 2025-09-07 12:11:40\n",
      "🖥️  Instances únicas: 1\n",
      "📦 Containers únicos: 1\n",
      "\n",
      "📋 Colunas do dataset:\n",
      "    1. pod_name\n",
      "    2. instance\n",
      "    3. instance_ip\n",
      "    4. instance_port\n",
      "    5. container\n",
      "    6. namespace\n",
      "    7. node\n",
      "    8. job\n",
      "    9. datetime_utc\n",
      "   10. timestamp\n",
      "   11. memory_bytes\n",
      "   12. memory_mb\n",
      "   13. memory_gb\n",
      "\n",
      "📋 Primeiros 5 registros:\n",
      "                            pod_name instance container        datetime_utc  memory_mb\n",
      "postgres-deployment-76d6f4778d-ccs8g      x86  postgres 2025-09-07 11:41:40      65.95\n",
      "postgres-deployment-76d6f4778d-ccs8g      x86  postgres 2025-09-07 11:42:10      65.95\n",
      "postgres-deployment-76d6f4778d-ccs8g      x86  postgres 2025-09-07 11:42:40      65.95\n",
      "postgres-deployment-76d6f4778d-ccs8g      x86  postgres 2025-09-07 11:43:10      65.95\n",
      "postgres-deployment-76d6f4778d-ccs8g      x86  postgres 2025-09-07 11:43:40      65.95\n",
      "\n",
      "📊 Estatísticas Gerais de Memória:\n",
      "   �� Mínima: 61.69 MB\n",
      "   🔺 Máxima: 65.96 MB\n",
      "   📊 Média: 64.75 MB\n",
      "   📏 Desvio Padrão: 1.71 MB\n",
      "\n",
      "�� Dataset completo salvo em: postgres_memory_with_instances_20250907_091140.csv\n",
      "💾 Resumo por instance salvo em: postgres_instances_summary_20250907_091140.csv\n",
      "\n",
      "================================================================================\n",
      "💡 EXEMPLO: Como filtrar por instance específica\n",
      "================================================================================\n",
      "Dados filtrados para instance 'x86':\n",
      "Total de registros: 61\n",
      "       datetime_utc container  memory_mb\n",
      "2025-09-07 11:41:40  postgres      65.95\n",
      "2025-09-07 11:42:10  postgres      65.95\n",
      "2025-09-07 11:42:40  postgres      65.95\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import re\n",
    "\n",
    "def query_prometheus_memory_with_instance(prometheus_url, pod_name, time_range=\"30m\"):\n",
    "    \"\"\"\n",
    "    Consulta memória do pod incluindo informações detalhadas de instance\n",
    "    \"\"\"\n",
    "    print(f\"\\n🔍 Consultando memória do pod: {pod_name}\")\n",
    "    \n",
    "    # Calcular timestamps Unix\n",
    "    end_time = int(time.time())\n",
    "    seconds = parse_time_range(time_range)\n",
    "    start_time = end_time - seconds\n",
    "    \n",
    "    # Construir a query\n",
    "    query = f'container_memory_usage_bytes{{pod=\"{pod_name}\", container!=\"POD\", container!=\"\"}}'\n",
    "    \n",
    "    # Parâmetros com timestamps Unix\n",
    "    params = {\n",
    "        'query': query,\n",
    "        'start': str(start_time),\n",
    "        'end': str(end_time),\n",
    "        'step': '30s'\n",
    "    }\n",
    "    \n",
    "    api_url = f\"{prometheus_url}/api/v1/query_range\"\n",
    "    \n",
    "    print(f\"🌐 URL da consulta: {api_url}\")\n",
    "    print(f\"📋 Query: {query}\")\n",
    "    print(f\"⏰ Start: {start_time} ({datetime.fromtimestamp(start_time)})\")\n",
    "    print(f\"⏰ End: {end_time} ({datetime.fromtimestamp(end_time)})\")\n",
    "    print(f\"📊 Período: {time_range}\")\n",
    "    \n",
    "    try:\n",
    "        print(\"📡 Fazendo requisição...\")\n",
    "        response = requests.get(api_url, params=params, timeout=30)\n",
    "        \n",
    "        print(f\"📊 Status HTTP: {response.status_code}\")\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"❌ Erro HTTP {response.status_code}\")\n",
    "            print(f\"Resposta: {response.text}\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        data = response.json()\n",
    "        \n",
    "        if data['status'] != 'success':\n",
    "            print(f\"❌ Erro na query Prometheus: {data.get('error', 'Erro desconhecido')}\")\n",
    "            print(f\"Tipo do erro: {data.get('errorType', 'N/A')}\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        results = data['data']['result']\n",
    "        \n",
    "        if not results:\n",
    "            print(\"⚠️  Nenhum dado encontrado para este pod\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        print(f\"✅ Encontrados {len(results)} séries de dados\")\n",
    "        \n",
    "        # Mostrar informações das instances encontradas\n",
    "        instances_found = set()\n",
    "        for result in results:\n",
    "            metric = result['metric']\n",
    "            instance = metric.get('instance', 'N/A')\n",
    "            container = metric.get('container', 'N/A')\n",
    "            instances_found.add(f\"{instance} (container: {container})\")\n",
    "        \n",
    "        print(\"\\n🖥️  Instances encontradas:\")\n",
    "        for instance_info in sorted(instances_found):\n",
    "            print(f\"   📍 {instance_info}\")\n",
    "        \n",
    "        # Processar dados\n",
    "        processed_data = []\n",
    "        \n",
    "        for result in results:\n",
    "            metric = result['metric']\n",
    "            values = result['values']\n",
    "            \n",
    "            # Extrair todas as informações disponíveis da métrica\n",
    "            pod_name_found = metric.get('pod', 'N/A')\n",
    "            instance = metric.get('instance', 'N/A')\n",
    "            container = metric.get('container', 'N/A')\n",
    "            namespace = metric.get('namespace', 'N/A')\n",
    "            node = metric.get('node', 'N/A')\n",
    "            job = metric.get('job', 'N/A')\n",
    "            \n",
    "            # Separar IP e porta da instance (se disponível)\n",
    "            instance_ip = 'N/A'\n",
    "            instance_port = 'N/A'\n",
    "            if instance and instance != 'N/A' and ':' in instance:\n",
    "                try:\n",
    "                    instance_ip, instance_port = instance.split(':')\n",
    "                except:\n",
    "                    instance_ip = instance\n",
    "            elif instance and instance != 'N/A':\n",
    "                instance_ip = instance\n",
    "            \n",
    "            print(f\"📦 Processando - Container: {container}, Instance: {instance}\")\n",
    "            \n",
    "            for timestamp, memory_bytes in values:\n",
    "                try:\n",
    "                    dt_utc = datetime.utcfromtimestamp(float(timestamp))\n",
    "                    processed_data.append({\n",
    "                        'pod_name': pod_name_found,\n",
    "                        'instance': instance,\n",
    "                        'instance_ip': instance_ip,\n",
    "                        'instance_port': instance_port,\n",
    "                        'container': container,\n",
    "                        'namespace': namespace,\n",
    "                        'node': node,\n",
    "                        'job': job,\n",
    "                        'datetime_utc': dt_utc.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                        'timestamp': float(timestamp),\n",
    "                        'memory_bytes': float(memory_bytes),\n",
    "                        'memory_mb': round(float(memory_bytes) / (1024 * 1024), 2),\n",
    "                        'memory_gb': round(float(memory_bytes) / (1024 * 1024 * 1024), 4)\n",
    "                    })\n",
    "                except (ValueError, TypeError) as e:\n",
    "                    print(f\"⚠️  Erro ao processar ponto de dados: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        if not processed_data:\n",
    "            print(\"❌ Nenhum dado válido foi processado\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        df = pd.DataFrame(processed_data)\n",
    "        df = df.sort_values(['instance', 'container', 'timestamp']).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"✅ Dataset criado com {len(df)} registros\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro inesperado: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def parse_time_range(time_range):\n",
    "    \"\"\"\n",
    "    Converte time_range (ex: \"30m\", \"1h\", \"2d\") para segundos\n",
    "    \"\"\"\n",
    "    match = re.match(r'(\\d+)([smhd])', time_range.lower())\n",
    "    if not match:\n",
    "        raise ValueError(f\"Formato de time_range inválido: {time_range}\")\n",
    "    \n",
    "    value = int(match.group(1))\n",
    "    unit = match.group(2)\n",
    "    \n",
    "    multipliers = {\n",
    "        's': 1,      # segundos\n",
    "        'm': 60,     # minutos\n",
    "        'h': 3600,   # horas\n",
    "        'd': 86400   # dias\n",
    "    }\n",
    "    \n",
    "    return value * multipliers[unit]\n",
    "\n",
    "def show_instance_summary(df):\n",
    "    \"\"\"\n",
    "    Mostra resumo das instances encontradas\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"🖥️  RESUMO DAS INSTANCES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Agrupar por instance\n",
    "    instance_summary = df.groupby(['instance', 'container']).agg({\n",
    "        'memory_mb': ['min', 'max', 'mean', 'count'],\n",
    "        'pod_name': 'first',\n",
    "        'namespace': 'first',\n",
    "        'node': 'first'\n",
    "    }).round(2)\n",
    "    \n",
    "    # Flatten column names\n",
    "    instance_summary.columns = ['_'.join(col).strip() for col in instance_summary.columns.values]\n",
    "    instance_summary = instance_summary.reset_index()\n",
    "    \n",
    "    for _, row in instance_summary.iterrows():\n",
    "        print(f\"\\n📍 Instance: {row['instance']}\")\n",
    "        print(f\"   �� Container: {row['container']}\")\n",
    "        print(f\"   🏷️  Pod: {row['pod_name_first']}\")\n",
    "        print(f\"   📂 Namespace: {row['namespace_first']}\")\n",
    "        print(f\"   🖥️  Node: {row['node_first']}\")\n",
    "        print(f\"   📊 Memória - Min: {row['memory_mb_min']} MB | Max: {row['memory_mb_max']} MB | Média: {row['memory_mb_mean']} MB\")\n",
    "        print(f\"   📈 Registros: {int(row['memory_mb_count'])}\")\n",
    "\n",
    "def list_postgres_pods_with_instances(prometheus_url):\n",
    "    \"\"\"\n",
    "    Lista pods PostgreSQL com suas respectivas instances\n",
    "    \"\"\"\n",
    "    print(\"\\n🔍 Buscando pods PostgreSQL e suas instances...\")\n",
    "    \n",
    "    query = 'container_memory_usage_bytes{container!=\"POD\", container!=\"\"}'\n",
    "    params = {'query': query}\n",
    "    api_url = f\"{prometheus_url}/api/v1/query\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(api_url, params=params, timeout=15)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"❌ Erro ao listar pods: {response.status_code}\")\n",
    "            return []\n",
    "        \n",
    "        data = response.json()\n",
    "        \n",
    "        if data['status'] != 'success':\n",
    "            print(f\"❌ Erro na query: {data.get('error')}\")\n",
    "            return []\n",
    "        \n",
    "        # Extrair pods PostgreSQL com instances\n",
    "        postgres_info = []\n",
    "        all_pods_info = []\n",
    "        \n",
    "        for result in data['data']['result']:\n",
    "            metric = result['metric']\n",
    "            pod_name = metric.get('pod', '')\n",
    "            instance = metric.get('instance', 'N/A')\n",
    "            container = metric.get('container', 'N/A')\n",
    "            namespace = metric.get('namespace', 'N/A')\n",
    "            \n",
    "            pod_info = {\n",
    "                'pod': pod_name,\n",
    "                'instance': instance,\n",
    "                'container': container,\n",
    "                'namespace': namespace\n",
    "            }\n",
    "            \n",
    "            if pod_name:\n",
    "                all_pods_info.append(pod_info)\n",
    "                if 'postgres' in pod_name.lower():\n",
    "                    postgres_info.append(pod_info)\n",
    "        \n",
    "        if postgres_info:\n",
    "            print(\"✅ Pods PostgreSQL encontrados:\")\n",
    "            for info in postgres_info:\n",
    "                print(f\"   📦 Pod: {info['pod']}\")\n",
    "                print(f\"      📍 Instance: {info['instance']}\")\n",
    "                print(f\"      🔧 Container: {info['container']}\")\n",
    "                print(f\"      📂 Namespace: {info['namespace']}\")\n",
    "                print()\n",
    "        else:\n",
    "            print(\"⚠️  Nenhum pod PostgreSQL encontrado\")\n",
    "            print(\"💡 Pods disponíveis (primeiros 5):\")\n",
    "            for info in all_pods_info[:5]:\n",
    "                print(f\"   📦 Pod: {info['pod']} | Instance: {info['instance']}\")\n",
    "        \n",
    "        return [info['pod'] for info in postgres_info]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro ao listar pods: {e}\")\n",
    "        return []\n",
    "\n",
    "def main():\n",
    "    # Configurações\n",
    "    PROMETHEUS_URL = \"http://192.168.242.131:9090\"\n",
    "    \n",
    "    print(\"🚀 Iniciando consulta ao Prometheus com informações de Instance\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Listar pods PostgreSQL com instances\n",
    "    postgres_pods = list_postgres_pods_with_instances(PROMETHEUS_URL)\n",
    "    \n",
    "    if postgres_pods:\n",
    "        pod_name = postgres_pods[0]\n",
    "        print(f\"\\n✅ Usando pod: {pod_name}\")\n",
    "    else:\n",
    "        pod_name = input(\"\\nDigite o nome exato do pod PostgreSQL: \").strip()\n",
    "        if not pod_name:\n",
    "            print(\"❌ Nome do pod não fornecido\")\n",
    "            return None\n",
    "    \n",
    "    # Executar consulta\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    df = query_prometheus_memory_with_instance(PROMETHEUS_URL, pod_name, \"30m\")\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"❌ Nenhum dado foi retornado\")\n",
    "        return None\n",
    "    \n",
    "    # Mostrar resumo das instances\n",
    "    show_instance_summary(df)\n",
    "    \n",
    "    # Exibir resultados detalhados\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"📊 DATASET COMPLETO\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"📈 Total de registros: {len(df)}\")\n",
    "    print(f\"⏰ Período: {df['datetime_utc'].min()} até {df['datetime_utc'].max()}\")\n",
    "    print(f\"🖥️  Instances únicas: {df['instance'].nunique()}\")\n",
    "    print(f\"📦 Containers únicos: {df['container'].nunique()}\")\n",
    "    \n",
    "    # Mostrar colunas disponíveis\n",
    "    print(f\"\\n📋 Colunas do dataset:\")\n",
    "    for i, col in enumerate(df.columns, 1):\n",
    "        print(f\"   {i:2d}. {col}\")\n",
    "    \n",
    "    print(f\"\\n📋 Primeiros 5 registros:\")\n",
    "    # Mostrar apenas colunas principais para visualização\n",
    "    display_cols = ['pod_name', 'instance', 'container', 'datetime_utc', 'memory_mb']\n",
    "    print(df[display_cols].head().to_string(index=False))\n",
    "    \n",
    "    print(f\"\\n📊 Estatísticas Gerais de Memória:\")\n",
    "    print(f\"   �� Mínima: {df['memory_mb'].min():.2f} MB\")\n",
    "    print(f\"   🔺 Máxima: {df['memory_mb'].max():.2f} MB\")\n",
    "    print(f\"   📊 Média: {df['memory_mb'].mean():.2f} MB\")\n",
    "    print(f\"   📏 Desvio Padrão: {df['memory_mb'].std():.2f} MB\")\n",
    "    \n",
    "    # Salvar arquivo com timestamp\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    output_file = f\"postgres_memory_with_instances_{timestamp}.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"\\n�� Dataset completo salvo em: {output_file}\")\n",
    "    \n",
    "    # Salvar resumo por instance\n",
    "    summary_file = f\"postgres_instances_summary_{timestamp}.csv\"\n",
    "    instance_summary = df.groupby(['instance', 'container']).agg({\n",
    "        'memory_mb': ['min', 'max', 'mean', 'std', 'count'],\n",
    "        'pod_name': 'first',\n",
    "        'namespace': 'first',\n",
    "        'node': 'first'\n",
    "    }).round(2)\n",
    "    instance_summary.to_csv(summary_file)\n",
    "    print(f\"💾 Resumo por instance salvo em: {summary_file}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset = main()\n",
    "    \n",
    "    # Exemplo de como filtrar por instance específica\n",
    "    if dataset is not None and not dataset.empty:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"💡 EXEMPLO: Como filtrar por instance específica\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        instances = dataset['instance'].unique()\n",
    "        if len(instances) > 0:\n",
    "            example_instance = instances[0]\n",
    "            filtered_df = dataset[dataset['instance'] == example_instance]\n",
    "            print(f\"Dados filtrados para instance '{example_instance}':\")\n",
    "            print(f\"Total de registros: {len(filtered_df)}\")\n",
    "            print(filtered_df[['datetime_utc', 'container', 'memory_mb']].head(3).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a154939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>pod</th>\n",
       "      <th>cpu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-09-07 11:35:13.859</td>\n",
       "      <td>postgres-deployment-76d6f4778d-ccs8g</td>\n",
       "      <td>32.653251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-09-07 11:35:33.830</td>\n",
       "      <td>postgres-deployment-76d6f4778d-ccs8g</td>\n",
       "      <td>32.658900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-09-07 11:35:46.481</td>\n",
       "      <td>postgres-deployment-76d6f4778d-ccs8g</td>\n",
       "      <td>32.661028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-09-07 11:36:00.848</td>\n",
       "      <td>postgres-deployment-76d6f4778d-ccs8g</td>\n",
       "      <td>32.663194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-09-07 11:36:17.275</td>\n",
       "      <td>postgres-deployment-76d6f4778d-ccs8g</td>\n",
       "      <td>32.665445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2025-09-07 11:43:37.589</td>\n",
       "      <td>postgres-deployment-76d6f4778d-ccs8g</td>\n",
       "      <td>0.054616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2025-09-07 11:43:52.151</td>\n",
       "      <td>postgres-deployment-76d6f4778d-ccs8g</td>\n",
       "      <td>0.054616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2025-09-07 11:44:12.135</td>\n",
       "      <td>postgres-deployment-76d6f4778d-ccs8g</td>\n",
       "      <td>0.054616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2025-09-07 11:44:23.583</td>\n",
       "      <td>postgres-deployment-76d6f4778d-ccs8g</td>\n",
       "      <td>0.054616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2025-09-07 11:44:52.066</td>\n",
       "      <td>postgres-deployment-76d6f4778d-ccs8g</td>\n",
       "      <td>0.054616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp                                   pod        cpu\n",
       "0   2025-09-07 11:35:13.859  postgres-deployment-76d6f4778d-ccs8g  32.653251\n",
       "1   2025-09-07 11:35:33.830  postgres-deployment-76d6f4778d-ccs8g  32.658900\n",
       "2   2025-09-07 11:35:46.481  postgres-deployment-76d6f4778d-ccs8g  32.661028\n",
       "3   2025-09-07 11:36:00.848  postgres-deployment-76d6f4778d-ccs8g  32.663194\n",
       "4   2025-09-07 11:36:17.275  postgres-deployment-76d6f4778d-ccs8g  32.665445\n",
       "..                      ...                                   ...        ...\n",
       "102 2025-09-07 11:43:37.589  postgres-deployment-76d6f4778d-ccs8g   0.054616\n",
       "103 2025-09-07 11:43:52.151  postgres-deployment-76d6f4778d-ccs8g   0.054616\n",
       "104 2025-09-07 11:44:12.135  postgres-deployment-76d6f4778d-ccs8g   0.054616\n",
       "105 2025-09-07 11:44:23.583  postgres-deployment-76d6f4778d-ccs8g   0.054616\n",
       "106 2025-09-07 11:44:52.066  postgres-deployment-76d6f4778d-ccs8g   0.054616\n",
       "\n",
       "[107 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bba1c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from seaborn) (2.3.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/ubuntu/.local/lib/python3.10/site-packages (from seaborn) (3.10.3)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/ubuntu/.local/lib/python3.10/site-packages (from seaborn) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.5)\n",
      "Requirement already satisfied: pillow>=8 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=1.2->seaborn) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ubuntu/.local/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9046ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Gerando Gráficos de Memória vs Tempo\n",
      "============================================================\n",
      "\n",
      "📊 Resumo dos dados coletados:\n",
      "   📈 Total de registros: 107\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'datetime'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 306\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;66;03m# Instalar dependências necessárias:\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;66;03m# pip install matplotlib seaborn requests pandas\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 290\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m📊 Resumo dos dados coletados:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   📈 Total de registros: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 290\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   ⏰ Período: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatetime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m até \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   📦 Containers: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontainer\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   🖥️  Instances: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstance\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:4107\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4107\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4109\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3817\u001b[0m     ):\n\u001b[1;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'datetime'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "def query_prometheus_memory_for_chart(prometheus_url, pod_name, time_range=\"30m\"):\n",
    "    \"\"\"\n",
    "    Consulta dados do Prometheus para gerar gráfico\n",
    "    \"\"\"\n",
    "    print(f\"🔍 Consultando dados para gráfico - Pod: {pod_name}\")\n",
    "    \n",
    "    # Calcular timestamps\n",
    "    end_time = int(time.time())\n",
    "    seconds = parse_time_range(time_range)\n",
    "    start_time = end_time - seconds\n",
    "\n",
    "  \n",
    "\n",
    "    query = f'container_memory_usage_bytes{{pod=~\".*{pod_name}.*\", container!=\"POD\", container!=\"\"}}'\n",
    "    \n",
    "    params = {\n",
    "        'query': query,\n",
    "        'start': str(start_time),\n",
    "        'end': str(end_time),\n",
    "        'step': '30s'\n",
    "    }\n",
    "    \n",
    "    api_url = f\"{prometheus_url}/api/v1/query_range\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(api_url, params=params, timeout=30)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"❌ Erro HTTP {response.status_code}\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        data = response.json()\n",
    "        \n",
    "        if data['status'] != 'success':\n",
    "            print(f\"❌ Erro Prometheus: {data.get('error')}\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        results = data['data']['result']\n",
    "        \n",
    "        if not results:\n",
    "            print(\"⚠️  Nenhum dado encontrado\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        processed_data = []\n",
    "        \n",
    "        for result in results:\n",
    "            metric = result['metric']\n",
    "            values = result['values']\n",
    "            \n",
    "            pod_name_found = metric.get('pod', 'N/A')\n",
    "            instance = metric.get('instance', 'N/A')\n",
    "            container = metric.get('container', 'N/A')\n",
    "            \n",
    "            for timestamp, memory_bytes in values:\n",
    "                try:\n",
    "                    dt_utc = datetime.utcfromtimestamp(float(timestamp))\n",
    "                    processed_data.append({\n",
    "                        'pod_name': pod_name_found,\n",
    "                        'instance': instance,\n",
    "                        'container': container,\n",
    "                        'datetime': dt_utc,\n",
    "                        'timestamp': float(timestamp),\n",
    "                        'memory_bytes': float(memory_bytes),\n",
    "                        'memory_mb': round(float(memory_bytes) / (1024 * 1024), 2),\n",
    "                        'memory_gb': round(float(memory_bytes) / (1024 * 1024 * 1024), 4)\n",
    "                    })\n",
    "                except (ValueError, TypeError):\n",
    "                    continue\n",
    "        \n",
    "        if not processed_data:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        df = pd.DataFrame(processed_data)\n",
    "        df = df.sort_values(['container', 'timestamp']).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"✅ {len(df)} registros coletados para {df['container'].nunique()} containers\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def parse_time_range(time_range):\n",
    "    \"\"\"Converte time_range para segundos\"\"\"\n",
    "    match = re.match(r'(\\d+)([smhd])', time_range.lower())\n",
    "    if not match:\n",
    "        raise ValueError(f\"Formato inválido: {time_range}\")\n",
    "    \n",
    "    value = int(match.group(1))\n",
    "    unit = match.group(2)\n",
    "    \n",
    "    multipliers = {'s': 1, 'm': 60, 'h': 3600, 'd': 86400}\n",
    "    return value * multipliers[unit]\n",
    "\n",
    "def create_memory_time_chart(df, pod_name, save_file=True):\n",
    "    \"\"\"\n",
    "    Cria gráfico de tempo vs memória\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        print(\"❌ Sem dados para gerar gráfico\")\n",
    "        return None\n",
    "    \n",
    "    # Configurar estilo\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "    sns.set_palette(\"husl\")\n",
    "    \n",
    "    # Criar figura\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    \n",
    "    # Agrupar por container\n",
    "    containers = df['container'].unique()\n",
    "    colors = plt.cm.Set3(range(len(containers)))\n",
    "    \n",
    "    for i, container in enumerate(containers):\n",
    "        container_data = df[df['container'] == container].copy()\n",
    "        container_data = container_data.sort_values('datetime')\n",
    "        \n",
    "        # Plotar linha\n",
    "        ax.plot(container_data['datetime'], \n",
    "                container_data['memory_mb'],\n",
    "                label=f'{container}',\n",
    "                linewidth=2,\n",
    "                marker='o',\n",
    "                markersize=3,\n",
    "                color=colors[i],\n",
    "                alpha=0.8)\n",
    "        \n",
    "        # Adicionar área sombreada\n",
    "        ax.fill_between(container_data['datetime'], \n",
    "                       container_data['memory_mb'],\n",
    "                       alpha=0.2,\n",
    "                       color=colors[i])\n",
    "    \n",
    "    # Configurar eixos\n",
    "    ax.set_xlabel('Tempo (UTC)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Memória (MB)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'Uso de Memória ao Longo do Tempo\\nPod: {pod_name}', \n",
    "                fontsize=14, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Formatação do eixo X (tempo)\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    ax.xaxis.set_major_locator(mdates.MinuteLocator(interval=5))\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Formatação do eixo Y (memória)\n",
    "    def format_mb(x, p):\n",
    "        if x >= 1000:\n",
    "            return f'{x/1000:.1f}GB'\n",
    "        return f'{x:.0f}MB'\n",
    "    \n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(format_mb))\n",
    "    \n",
    "    # Grid\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Legenda\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "    \n",
    "    # Estatísticas no gráfico\n",
    "    stats_text = f\"\"\"Estatísticas Gerais:\n",
    "• Mín: {df['memory_mb'].min():.1f} MB\n",
    "• Máx: {df['memory_mb'].max():.1f} MB  \n",
    "• Média: {df['memory_mb'].mean():.1f} MB\n",
    "• Período: {df['datetime'].min().strftime('%H:%M')} - {df['datetime'].max().strftime('%H:%M')}\"\"\"\n",
    "    \n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, \n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', \n",
    "            facecolor='white', alpha=0.8), fontsize=9)\n",
    "    \n",
    "    # Ajustar layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salvar arquivo\n",
    "    if save_file:\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f'postgres_memory_chart_{timestamp}.png'\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        print(f\"📊 Gráfico salvo como: {filename}\")\n",
    "    \n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "def create_multiple_charts(df, pod_name):\n",
    "    \"\"\"\n",
    "    Cria múltiplos tipos de gráficos\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    # 1. Gráfico de linha principal\n",
    "    print(\"📊 Criando gráfico de linha...\")\n",
    "    create_memory_time_chart(df, pod_name, save_file=True)\n",
    "    \n",
    "    # 2. Gráfico por container (subplots)\n",
    "    if df['container'].nunique() > 1:\n",
    "        print(\"�� Criando gráficos separados por container...\")\n",
    "        \n",
    "        containers = df['container'].unique()\n",
    "        fig, axes = plt.subplots(len(containers), 1, figsize=(15, 4*len(containers)))\n",
    "        \n",
    "        if len(containers) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for i, container in enumerate(containers):\n",
    "            container_data = df[df['container'] == container].copy()\n",
    "            container_data = container_data.sort_values('datetime')\n",
    "            \n",
    "            axes[i].plot(container_data['datetime'], \n",
    "                        container_data['memory_mb'],\n",
    "                        linewidth=2, marker='o', markersize=2)\n",
    "            \n",
    "            axes[i].fill_between(container_data['datetime'], \n",
    "                               container_data['memory_mb'], alpha=0.3)\n",
    "            \n",
    "            axes[i].set_title(f'Container: {container}', fontweight='bold')\n",
    "            axes[i].set_ylabel('Memória (MB)')\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "            axes[i].xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "            \n",
    "            # Estatísticas por container\n",
    "            stats = f\"Min: {container_data['memory_mb'].min():.1f}MB | Max: {container_data['memory_mb'].max():.1f}MB | Média: {container_data['memory_mb'].mean():.1f}MB\"\n",
    "            axes[i].text(0.02, 0.95, stats, transform=axes[i].transAxes, \n",
    "                        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7),\n",
    "                        fontsize=8)\n",
    "        \n",
    "        plt.xlabel('Tempo (UTC)')\n",
    "        plt.suptitle(f'Uso de Memória por Container - Pod: {pod_name}', \n",
    "                    fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        filename = f'postgres_memory_by_container_{timestamp}.png'\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        print(f\"📊 Gráfico por container salvo: {filename}\")\n",
    "        plt.show()\n",
    "    \n",
    "    # 3. Histograma de distribuição de memória\n",
    "    print(\"📊 Criando histograma de distribuição...\")\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    containers = df['container'].unique()\n",
    "    colors = plt.cm.Set3(range(len(containers)))\n",
    "    \n",
    "    for i, container in enumerate(containers):\n",
    "        container_data = df[df['container'] == container]\n",
    "        plt.hist(container_data['memory_mb'], bins=30, alpha=0.7, \n",
    "                label=container, color=colors[i], edgecolor='black')\n",
    "    \n",
    "    plt.xlabel('Memória (MB)', fontweight='bold')\n",
    "    plt.ylabel('Frequência', fontweight='bold')\n",
    "    plt.title(f'Distribuição do Uso de Memória - Pod: {pod_name}', \n",
    "              fontweight='bold', pad=20)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    filename = f'postgres_memory_distribution_{timestamp}.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"📊 Histograma salvo: {filename}\")\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    # Configurações\n",
    "    PROMETHEUS_URL = \"http://192.168.242.131:9090\"\n",
    "    POD_NAME = \"postgres\"  # Ajuste conforme necessário\n",
    "    TIME_RANGE = \"130m\"     # Período de consulta\n",
    "    \n",
    "    print(\"🚀 Gerando Gráficos de Memória vs Tempo\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Consultar dados\n",
    "    df = query_prometheus_memory_for_chart(PROMETHEUS_URL, POD_NAME, TIME_RANGE)\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"❌ Sem dados para gerar gráficos\")\n",
    "        return\n",
    "    \n",
    "    # Mostrar resumo dos dados\n",
    "    print(f\"\\n📊 Resumo dos dados coletados:\")\n",
    "    print(f\"   📈 Total de registros: {len(df)}\")\n",
    "    print(f\"   ⏰ Período: {df['datetime'].min()} até {df['datetime'].max()}\")\n",
    "    print(f\"   📦 Containers: {', '.join(df['container'].unique())}\")\n",
    "    print(f\"   🖥️  Instances: {', '.join(df['instance'].unique())}\")\n",
    "    \n",
    "    # Criar gráficos\n",
    "    print(f\"\\n📊 Gerando gráficos...\")\n",
    "    create_multiple_charts(df, POD_NAME)\n",
    "    \n",
    "    print(f\"\\n✅ Gráficos gerados com sucesso!\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Instalar dependências necessárias:\n",
    "    # pip install matplotlib seaborn requests pandas\n",
    "    \n",
    "    dataset = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
