{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad015db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# URL da API Prometheus\n",
    "url = 'http://192.168.242.131:9090/api/v1/query?query=container_cpu_usage_seconds_total{pod=~\".*postgres.*\"}[10m]'\n",
    "\n",
    "# Fazendo a requisi√ß√£o GET\n",
    "response = requests.get(url)\n",
    "data = response.json()  # Converte a resposta para dict\n",
    "\n",
    "# Verifica se h√° resultados e estrutura esperada\n",
    "results = data.get('data', {}).get('result', [])\n",
    "\n",
    "# Lista para armazenar os registros\n",
    "records = []\n",
    "\n",
    "# Processa cada resultado\n",
    "for item in results:\n",
    "    # Extrai a s√©rie temporal (samples)\n",
    "    for value in item.get('values', []):\n",
    "        ts = float(value[0])  # Timestamp UNIX\n",
    "        cpu_val = float(value[1])\n",
    "        # Converte timestamp para Data/Hora leg√≠vel\n",
    "        dt = datetime.utcfromtimestamp(ts)\n",
    "        \n",
    "        # Extrai o nome do pod dos labels\n",
    "        pod_name = item['metric'].get('pod', 'N/A')\n",
    "        records.append({\"timestamp\": dt, \"pod\": pod_name, \"cpu\": cpu_val})\n",
    "\n",
    "# Cria DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "#df = df.sort_values(by='timestamp', ascending=False)\n",
    "# Mostra resultado\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4df7a0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Iniciando consulta ao Prometheus com informa√ß√µes de Instance\n",
      "================================================================================\n",
      "\n",
      "üîç Buscando pods PostgreSQL e suas instances...\n",
      "‚úÖ Pods PostgreSQL encontrados:\n",
      "   üì¶ Pod: postgres-deployment-76d6f4778d-ccs8g\n",
      "      üìç Instance: x86\n",
      "      üîß Container: postgres\n",
      "      üìÇ Namespace: stress-app\n",
      "\n",
      "\n",
      "‚úÖ Usando pod: postgres-deployment-76d6f4778d-ccs8g\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üîç Consultando mem√≥ria do pod: postgres-deployment-76d6f4778d-ccs8g\n",
      "üåê URL da consulta: http://192.168.242.131:9090/api/v1/query_range\n",
      "üìã Query: container_memory_usage_bytes{pod=\"postgres-deployment-76d6f4778d-ccs8g\", container!=\"POD\", container!=\"\"}\n",
      "‚è∞ Start: 1757245300 (2025-09-07 08:41:40)\n",
      "‚è∞ End: 1757247100 (2025-09-07 09:11:40)\n",
      "üìä Per√≠odo: 30m\n",
      "üì° Fazendo requisi√ß√£o...\n",
      "üìä Status HTTP: 200\n",
      "‚úÖ Encontrados 1 s√©ries de dados\n",
      "\n",
      "üñ•Ô∏è  Instances encontradas:\n",
      "   üìç x86 (container: postgres)\n",
      "üì¶ Processando - Container: postgres, Instance: x86\n",
      "‚úÖ Dataset criado com 61 registros\n",
      "\n",
      "================================================================================\n",
      "üñ•Ô∏è  RESUMO DAS INSTANCES\n",
      "================================================================================\n",
      "\n",
      "üìç Instance: x86\n",
      "   ÔøΩÔøΩ Container: postgres\n",
      "   üè∑Ô∏è  Pod: postgres-deployment-76d6f4778d-ccs8g\n",
      "   üìÇ Namespace: stress-app\n",
      "   üñ•Ô∏è  Node: N/A\n",
      "   üìä Mem√≥ria - Min: 61.69 MB | Max: 65.96 MB | M√©dia: 64.75 MB\n",
      "   üìà Registros: 61\n",
      "\n",
      "================================================================================\n",
      "üìä DATASET COMPLETO\n",
      "================================================================================\n",
      "üìà Total de registros: 61\n",
      "‚è∞ Per√≠odo: 2025-09-07 11:41:40 at√© 2025-09-07 12:11:40\n",
      "üñ•Ô∏è  Instances √∫nicas: 1\n",
      "üì¶ Containers √∫nicos: 1\n",
      "\n",
      "üìã Colunas do dataset:\n",
      "    1. pod_name\n",
      "    2. instance\n",
      "    3. instance_ip\n",
      "    4. instance_port\n",
      "    5. container\n",
      "    6. namespace\n",
      "    7. node\n",
      "    8. job\n",
      "    9. datetime_utc\n",
      "   10. timestamp\n",
      "   11. memory_bytes\n",
      "   12. memory_mb\n",
      "   13. memory_gb\n",
      "\n",
      "üìã Primeiros 5 registros:\n",
      "                            pod_name instance container        datetime_utc  memory_mb\n",
      "postgres-deployment-76d6f4778d-ccs8g      x86  postgres 2025-09-07 11:41:40      65.95\n",
      "postgres-deployment-76d6f4778d-ccs8g      x86  postgres 2025-09-07 11:42:10      65.95\n",
      "postgres-deployment-76d6f4778d-ccs8g      x86  postgres 2025-09-07 11:42:40      65.95\n",
      "postgres-deployment-76d6f4778d-ccs8g      x86  postgres 2025-09-07 11:43:10      65.95\n",
      "postgres-deployment-76d6f4778d-ccs8g      x86  postgres 2025-09-07 11:43:40      65.95\n",
      "\n",
      "üìä Estat√≠sticas Gerais de Mem√≥ria:\n",
      "   ÔøΩÔøΩ M√≠nima: 61.69 MB\n",
      "   üî∫ M√°xima: 65.96 MB\n",
      "   üìä M√©dia: 64.75 MB\n",
      "   üìè Desvio Padr√£o: 1.71 MB\n",
      "\n",
      "ÔøΩÔøΩ Dataset completo salvo em: postgres_memory_with_instances_20250907_091140.csv\n",
      "üíæ Resumo por instance salvo em: postgres_instances_summary_20250907_091140.csv\n",
      "\n",
      "================================================================================\n",
      "üí° EXEMPLO: Como filtrar por instance espec√≠fica\n",
      "================================================================================\n",
      "Dados filtrados para instance 'x86':\n",
      "Total de registros: 61\n",
      "       datetime_utc container  memory_mb\n",
      "2025-09-07 11:41:40  postgres      65.95\n",
      "2025-09-07 11:42:10  postgres      65.95\n",
      "2025-09-07 11:42:40  postgres      65.95\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import re\n",
    "\n",
    "def query_prometheus_memory_with_instance(prometheus_url, pod_name, time_range=\"30m\"):\n",
    "    \"\"\"\n",
    "    Consulta mem√≥ria do pod incluindo informa√ß√µes detalhadas de instance\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîç Consultando mem√≥ria do pod: {pod_name}\")\n",
    "    \n",
    "    # Calcular timestamps Unix\n",
    "    end_time = int(time.time())\n",
    "    seconds = parse_time_range(time_range)\n",
    "    start_time = end_time - seconds\n",
    "    \n",
    "    # Construir a query\n",
    "    query = f'container_memory_usage_bytes{{pod=\"{pod_name}\", container!=\"POD\", container!=\"\"}}'\n",
    "    \n",
    "    # Par√¢metros com timestamps Unix\n",
    "    params = {\n",
    "        'query': query,\n",
    "        'start': str(start_time),\n",
    "        'end': str(end_time),\n",
    "        'step': '30s'\n",
    "    }\n",
    "    \n",
    "    api_url = f\"{prometheus_url}/api/v1/query_range\"\n",
    "    \n",
    "    print(f\"üåê URL da consulta: {api_url}\")\n",
    "    print(f\"üìã Query: {query}\")\n",
    "    print(f\"‚è∞ Start: {start_time} ({datetime.fromtimestamp(start_time)})\")\n",
    "    print(f\"‚è∞ End: {end_time} ({datetime.fromtimestamp(end_time)})\")\n",
    "    print(f\"üìä Per√≠odo: {time_range}\")\n",
    "    \n",
    "    try:\n",
    "        print(\"üì° Fazendo requisi√ß√£o...\")\n",
    "        response = requests.get(api_url, params=params, timeout=30)\n",
    "        \n",
    "        print(f\"üìä Status HTTP: {response.status_code}\")\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"‚ùå Erro HTTP {response.status_code}\")\n",
    "            print(f\"Resposta: {response.text}\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        data = response.json()\n",
    "        \n",
    "        if data['status'] != 'success':\n",
    "            print(f\"‚ùå Erro na query Prometheus: {data.get('error', 'Erro desconhecido')}\")\n",
    "            print(f\"Tipo do erro: {data.get('errorType', 'N/A')}\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        results = data['data']['result']\n",
    "        \n",
    "        if not results:\n",
    "            print(\"‚ö†Ô∏è  Nenhum dado encontrado para este pod\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        print(f\"‚úÖ Encontrados {len(results)} s√©ries de dados\")\n",
    "        \n",
    "        # Mostrar informa√ß√µes das instances encontradas\n",
    "        instances_found = set()\n",
    "        for result in results:\n",
    "            metric = result['metric']\n",
    "            instance = metric.get('instance', 'N/A')\n",
    "            container = metric.get('container', 'N/A')\n",
    "            instances_found.add(f\"{instance} (container: {container})\")\n",
    "        \n",
    "        print(\"\\nüñ•Ô∏è  Instances encontradas:\")\n",
    "        for instance_info in sorted(instances_found):\n",
    "            print(f\"   üìç {instance_info}\")\n",
    "        \n",
    "        # Processar dados\n",
    "        processed_data = []\n",
    "        \n",
    "        for result in results:\n",
    "            metric = result['metric']\n",
    "            values = result['values']\n",
    "            \n",
    "            # Extrair todas as informa√ß√µes dispon√≠veis da m√©trica\n",
    "            pod_name_found = metric.get('pod', 'N/A')\n",
    "            instance = metric.get('instance', 'N/A')\n",
    "            container = metric.get('container', 'N/A')\n",
    "            namespace = metric.get('namespace', 'N/A')\n",
    "            node = metric.get('node', 'N/A')\n",
    "            job = metric.get('job', 'N/A')\n",
    "            \n",
    "            # Separar IP e porta da instance (se dispon√≠vel)\n",
    "            instance_ip = 'N/A'\n",
    "            instance_port = 'N/A'\n",
    "            if instance and instance != 'N/A' and ':' in instance:\n",
    "                try:\n",
    "                    instance_ip, instance_port = instance.split(':')\n",
    "                except:\n",
    "                    instance_ip = instance\n",
    "            elif instance and instance != 'N/A':\n",
    "                instance_ip = instance\n",
    "            \n",
    "            print(f\"üì¶ Processando - Container: {container}, Instance: {instance}\")\n",
    "            \n",
    "            for timestamp, memory_bytes in values:\n",
    "                try:\n",
    "                    dt_utc = datetime.utcfromtimestamp(float(timestamp))\n",
    "                    processed_data.append({\n",
    "                        'pod_name': pod_name_found,\n",
    "                        'instance': instance,\n",
    "                        'instance_ip': instance_ip,\n",
    "                        'instance_port': instance_port,\n",
    "                        'container': container,\n",
    "                        'namespace': namespace,\n",
    "                        'node': node,\n",
    "                        'job': job,\n",
    "                        'datetime_utc': dt_utc.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                        'timestamp': float(timestamp),\n",
    "                        'memory_bytes': float(memory_bytes),\n",
    "                        'memory_mb': round(float(memory_bytes) / (1024 * 1024), 2),\n",
    "                        'memory_gb': round(float(memory_bytes) / (1024 * 1024 * 1024), 4)\n",
    "                    })\n",
    "                except (ValueError, TypeError) as e:\n",
    "                    print(f\"‚ö†Ô∏è  Erro ao processar ponto de dados: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        if not processed_data:\n",
    "            print(\"‚ùå Nenhum dado v√°lido foi processado\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        df = pd.DataFrame(processed_data)\n",
    "        df = df.sort_values(['instance', 'container', 'timestamp']).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"‚úÖ Dataset criado com {len(df)} registros\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro inesperado: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def parse_time_range(time_range):\n",
    "    \"\"\"\n",
    "    Converte time_range (ex: \"30m\", \"1h\", \"2d\") para segundos\n",
    "    \"\"\"\n",
    "    match = re.match(r'(\\d+)([smhd])', time_range.lower())\n",
    "    if not match:\n",
    "        raise ValueError(f\"Formato de time_range inv√°lido: {time_range}\")\n",
    "    \n",
    "    value = int(match.group(1))\n",
    "    unit = match.group(2)\n",
    "    \n",
    "    multipliers = {\n",
    "        's': 1,      # segundos\n",
    "        'm': 60,     # minutos\n",
    "        'h': 3600,   # horas\n",
    "        'd': 86400   # dias\n",
    "    }\n",
    "    \n",
    "    return value * multipliers[unit]\n",
    "\n",
    "def show_instance_summary(df):\n",
    "    \"\"\"\n",
    "    Mostra resumo das instances encontradas\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üñ•Ô∏è  RESUMO DAS INSTANCES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Agrupar por instance\n",
    "    instance_summary = df.groupby(['instance', 'container']).agg({\n",
    "        'memory_mb': ['min', 'max', 'mean', 'count'],\n",
    "        'pod_name': 'first',\n",
    "        'namespace': 'first',\n",
    "        'node': 'first'\n",
    "    }).round(2)\n",
    "    \n",
    "    # Flatten column names\n",
    "    instance_summary.columns = ['_'.join(col).strip() for col in instance_summary.columns.values]\n",
    "    instance_summary = instance_summary.reset_index()\n",
    "    \n",
    "    for _, row in instance_summary.iterrows():\n",
    "        print(f\"\\nüìç Instance: {row['instance']}\")\n",
    "        print(f\"   ÔøΩÔøΩ Container: {row['container']}\")\n",
    "        print(f\"   üè∑Ô∏è  Pod: {row['pod_name_first']}\")\n",
    "        print(f\"   üìÇ Namespace: {row['namespace_first']}\")\n",
    "        print(f\"   üñ•Ô∏è  Node: {row['node_first']}\")\n",
    "        print(f\"   üìä Mem√≥ria - Min: {row['memory_mb_min']} MB | Max: {row['memory_mb_max']} MB | M√©dia: {row['memory_mb_mean']} MB\")\n",
    "        print(f\"   üìà Registros: {int(row['memory_mb_count'])}\")\n",
    "\n",
    "def list_postgres_pods_with_instances(prometheus_url):\n",
    "    \"\"\"\n",
    "    Lista pods PostgreSQL com suas respectivas instances\n",
    "    \"\"\"\n",
    "    print(\"\\nüîç Buscando pods PostgreSQL e suas instances...\")\n",
    "    \n",
    "    query = 'container_memory_usage_bytes{container!=\"POD\", container!=\"\"}'\n",
    "    params = {'query': query}\n",
    "    api_url = f\"{prometheus_url}/api/v1/query\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(api_url, params=params, timeout=15)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"‚ùå Erro ao listar pods: {response.status_code}\")\n",
    "            return []\n",
    "        \n",
    "        data = response.json()\n",
    "        \n",
    "        if data['status'] != 'success':\n",
    "            print(f\"‚ùå Erro na query: {data.get('error')}\")\n",
    "            return []\n",
    "        \n",
    "        # Extrair pods PostgreSQL com instances\n",
    "        postgres_info = []\n",
    "        all_pods_info = []\n",
    "        \n",
    "        for result in data['data']['result']:\n",
    "            metric = result['metric']\n",
    "            pod_name = metric.get('pod', '')\n",
    "            instance = metric.get('instance', 'N/A')\n",
    "            container = metric.get('container', 'N/A')\n",
    "            namespace = metric.get('namespace', 'N/A')\n",
    "            \n",
    "            pod_info = {\n",
    "                'pod': pod_name,\n",
    "                'instance': instance,\n",
    "                'container': container,\n",
    "                'namespace': namespace\n",
    "            }\n",
    "            \n",
    "            if pod_name:\n",
    "                all_pods_info.append(pod_info)\n",
    "                if 'postgres' in pod_name.lower():\n",
    "                    postgres_info.append(pod_info)\n",
    "        \n",
    "        if postgres_info:\n",
    "            print(\"‚úÖ Pods PostgreSQL encontrados:\")\n",
    "            for info in postgres_info:\n",
    "                print(f\"   üì¶ Pod: {info['pod']}\")\n",
    "                print(f\"      üìç Instance: {info['instance']}\")\n",
    "                print(f\"      üîß Container: {info['container']}\")\n",
    "                print(f\"      üìÇ Namespace: {info['namespace']}\")\n",
    "                print()\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  Nenhum pod PostgreSQL encontrado\")\n",
    "            print(\"üí° Pods dispon√≠veis (primeiros 5):\")\n",
    "            for info in all_pods_info[:5]:\n",
    "                print(f\"   üì¶ Pod: {info['pod']} | Instance: {info['instance']}\")\n",
    "        \n",
    "        return [info['pod'] for info in postgres_info]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao listar pods: {e}\")\n",
    "        return []\n",
    "\n",
    "def main():\n",
    "    # Configura√ß√µes\n",
    "    PROMETHEUS_URL = \"http://192.168.242.131:9090\"\n",
    "    \n",
    "    print(\"üöÄ Iniciando consulta ao Prometheus com informa√ß√µes de Instance\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Listar pods PostgreSQL com instances\n",
    "    postgres_pods = list_postgres_pods_with_instances(PROMETHEUS_URL)\n",
    "    \n",
    "    if postgres_pods:\n",
    "        pod_name = postgres_pods[0]\n",
    "        print(f\"\\n‚úÖ Usando pod: {pod_name}\")\n",
    "    else:\n",
    "        pod_name = input(\"\\nDigite o nome exato do pod PostgreSQL: \").strip()\n",
    "        if not pod_name:\n",
    "            print(\"‚ùå Nome do pod n√£o fornecido\")\n",
    "            return None\n",
    "    \n",
    "    # Executar consulta\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    df = query_prometheus_memory_with_instance(PROMETHEUS_URL, pod_name, \"30m\")\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"‚ùå Nenhum dado foi retornado\")\n",
    "        return None\n",
    "    \n",
    "    # Mostrar resumo das instances\n",
    "    show_instance_summary(df)\n",
    "    \n",
    "    # Exibir resultados detalhados\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìä DATASET COMPLETO\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"üìà Total de registros: {len(df)}\")\n",
    "    print(f\"‚è∞ Per√≠odo: {df['datetime_utc'].min()} at√© {df['datetime_utc'].max()}\")\n",
    "    print(f\"üñ•Ô∏è  Instances √∫nicas: {df['instance'].nunique()}\")\n",
    "    print(f\"üì¶ Containers √∫nicos: {df['container'].nunique()}\")\n",
    "    \n",
    "    # Mostrar colunas dispon√≠veis\n",
    "    print(f\"\\nüìã Colunas do dataset:\")\n",
    "    for i, col in enumerate(df.columns, 1):\n",
    "        print(f\"   {i:2d}. {col}\")\n",
    "    \n",
    "    print(f\"\\nüìã Primeiros 5 registros:\")\n",
    "    # Mostrar apenas colunas principais para visualiza√ß√£o\n",
    "    display_cols = ['pod_name', 'instance', 'container', 'datetime_utc', 'memory_mb']\n",
    "    print(df[display_cols].head().to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nüìä Estat√≠sticas Gerais de Mem√≥ria:\")\n",
    "    print(f\"   ÔøΩÔøΩ M√≠nima: {df['memory_mb'].min():.2f} MB\")\n",
    "    print(f\"   üî∫ M√°xima: {df['memory_mb'].max():.2f} MB\")\n",
    "    print(f\"   üìä M√©dia: {df['memory_mb'].mean():.2f} MB\")\n",
    "    print(f\"   üìè Desvio Padr√£o: {df['memory_mb'].std():.2f} MB\")\n",
    "    \n",
    "    # Salvar arquivo com timestamp\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    output_file = f\"postgres_memory_with_instances_{timestamp}.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nÔøΩÔøΩ Dataset completo salvo em: {output_file}\")\n",
    "    \n",
    "    # Salvar resumo por instance\n",
    "    summary_file = f\"postgres_instances_summary_{timestamp}.csv\"\n",
    "    instance_summary = df.groupby(['instance', 'container']).agg({\n",
    "        'memory_mb': ['min', 'max', 'mean', 'std', 'count'],\n",
    "        'pod_name': 'first',\n",
    "        'namespace': 'first',\n",
    "        'node': 'first'\n",
    "    }).round(2)\n",
    "    instance_summary.to_csv(summary_file)\n",
    "    print(f\"üíæ Resumo por instance salvo em: {summary_file}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset = main()\n",
    "    \n",
    "    # Exemplo de como filtrar por instance espec√≠fica\n",
    "    if dataset is not None and not dataset.empty:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üí° EXEMPLO: Como filtrar por instance espec√≠fica\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        instances = dataset['instance'].unique()\n",
    "        if len(instances) > 0:\n",
    "            example_instance = instances[0]\n",
    "            filtered_df = dataset[dataset['instance'] == example_instance]\n",
    "            print(f\"Dados filtrados para instance '{example_instance}':\")\n",
    "            print(f\"Total de registros: {len(filtered_df)}\")\n",
    "            print(filtered_df[['datetime_utc', 'container', 'memory_mb']].head(3).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a154939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>pod</th>\n",
       "      <th>cpu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-09-07 11:35:13.859</td>\n",
       "      <td>postgres-deployment-76d6f4778d-ccs8g</td>\n",
       "      <td>32.653251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-09-07 11:35:33.830</td>\n",
       "      <td>postgres-deployment-76d6f4778d-ccs8g</td>\n",
       "      <td>32.658900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-09-07 11:35:46.481</td>\n",
       "      <td>postgres-deployment-76d6f4778d-ccs8g</td>\n",
       "      <td>32.661028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-09-07 11:36:00.848</td>\n",
       "      <td>postgres-deployment-76d6f4778d-ccs8g</td>\n",
       "      <td>32.663194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-09-07 11:36:17.275</td>\n",
       "      <td>postgres-deployment-76d6f4778d-ccs8g</td>\n",
       "      <td>32.665445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2025-09-07 11:43:37.589</td>\n",
       "      <td>postgres-deployment-76d6f4778d-ccs8g</td>\n",
       "      <td>0.054616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2025-09-07 11:43:52.151</td>\n",
       "      <td>postgres-deployment-76d6f4778d-ccs8g</td>\n",
       "      <td>0.054616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2025-09-07 11:44:12.135</td>\n",
       "      <td>postgres-deployment-76d6f4778d-ccs8g</td>\n",
       "      <td>0.054616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2025-09-07 11:44:23.583</td>\n",
       "      <td>postgres-deployment-76d6f4778d-ccs8g</td>\n",
       "      <td>0.054616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2025-09-07 11:44:52.066</td>\n",
       "      <td>postgres-deployment-76d6f4778d-ccs8g</td>\n",
       "      <td>0.054616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp                                   pod        cpu\n",
       "0   2025-09-07 11:35:13.859  postgres-deployment-76d6f4778d-ccs8g  32.653251\n",
       "1   2025-09-07 11:35:33.830  postgres-deployment-76d6f4778d-ccs8g  32.658900\n",
       "2   2025-09-07 11:35:46.481  postgres-deployment-76d6f4778d-ccs8g  32.661028\n",
       "3   2025-09-07 11:36:00.848  postgres-deployment-76d6f4778d-ccs8g  32.663194\n",
       "4   2025-09-07 11:36:17.275  postgres-deployment-76d6f4778d-ccs8g  32.665445\n",
       "..                      ...                                   ...        ...\n",
       "102 2025-09-07 11:43:37.589  postgres-deployment-76d6f4778d-ccs8g   0.054616\n",
       "103 2025-09-07 11:43:52.151  postgres-deployment-76d6f4778d-ccs8g   0.054616\n",
       "104 2025-09-07 11:44:12.135  postgres-deployment-76d6f4778d-ccs8g   0.054616\n",
       "105 2025-09-07 11:44:23.583  postgres-deployment-76d6f4778d-ccs8g   0.054616\n",
       "106 2025-09-07 11:44:52.066  postgres-deployment-76d6f4778d-ccs8g   0.054616\n",
       "\n",
       "[107 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bba1c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m294.9/294.9 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from seaborn) (2.3.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/ubuntu/.local/lib/python3.10/site-packages (from seaborn) (3.10.3)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/ubuntu/.local/lib/python3.10/site-packages (from seaborn) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.5)\n",
      "Requirement already satisfied: pillow>=8 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=1.2->seaborn) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ubuntu/.local/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9046ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Gerando Gr√°ficos de Mem√≥ria vs Tempo\n",
      "============================================================\n",
      "\n",
      "üìä Resumo dos dados coletados:\n",
      "   üìà Total de registros: 107\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'datetime'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 306\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;66;03m# Instalar depend√™ncias necess√°rias:\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;66;03m# pip install matplotlib seaborn requests pandas\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 290\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müìä Resumo dos dados coletados:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   üìà Total de registros: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 290\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   ‚è∞ Per√≠odo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatetime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at√© \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   üì¶ Containers: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontainer\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   üñ•Ô∏è  Instances: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstance\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:4107\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4107\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4109\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3817\u001b[0m     ):\n\u001b[1;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'datetime'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "def query_prometheus_memory_for_chart(prometheus_url, pod_name, time_range=\"30m\"):\n",
    "    \"\"\"\n",
    "    Consulta dados do Prometheus para gerar gr√°fico\n",
    "    \"\"\"\n",
    "    print(f\"üîç Consultando dados para gr√°fico - Pod: {pod_name}\")\n",
    "    \n",
    "    # Calcular timestamps\n",
    "    end_time = int(time.time())\n",
    "    seconds = parse_time_range(time_range)\n",
    "    start_time = end_time - seconds\n",
    "\n",
    "  \n",
    "\n",
    "    query = f'container_memory_usage_bytes{{pod=~\".*{pod_name}.*\", container!=\"POD\", container!=\"\"}}'\n",
    "    \n",
    "    params = {\n",
    "        'query': query,\n",
    "        'start': str(start_time),\n",
    "        'end': str(end_time),\n",
    "        'step': '30s'\n",
    "    }\n",
    "    \n",
    "    api_url = f\"{prometheus_url}/api/v1/query_range\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(api_url, params=params, timeout=30)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"‚ùå Erro HTTP {response.status_code}\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        data = response.json()\n",
    "        \n",
    "        if data['status'] != 'success':\n",
    "            print(f\"‚ùå Erro Prometheus: {data.get('error')}\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        results = data['data']['result']\n",
    "        \n",
    "        if not results:\n",
    "            print(\"‚ö†Ô∏è  Nenhum dado encontrado\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        processed_data = []\n",
    "        \n",
    "        for result in results:\n",
    "            metric = result['metric']\n",
    "            values = result['values']\n",
    "            \n",
    "            pod_name_found = metric.get('pod', 'N/A')\n",
    "            instance = metric.get('instance', 'N/A')\n",
    "            container = metric.get('container', 'N/A')\n",
    "            \n",
    "            for timestamp, memory_bytes in values:\n",
    "                try:\n",
    "                    dt_utc = datetime.utcfromtimestamp(float(timestamp))\n",
    "                    processed_data.append({\n",
    "                        'pod_name': pod_name_found,\n",
    "                        'instance': instance,\n",
    "                        'container': container,\n",
    "                        'datetime': dt_utc,\n",
    "                        'timestamp': float(timestamp),\n",
    "                        'memory_bytes': float(memory_bytes),\n",
    "                        'memory_mb': round(float(memory_bytes) / (1024 * 1024), 2),\n",
    "                        'memory_gb': round(float(memory_bytes) / (1024 * 1024 * 1024), 4)\n",
    "                    })\n",
    "                except (ValueError, TypeError):\n",
    "                    continue\n",
    "        \n",
    "        if not processed_data:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        df = pd.DataFrame(processed_data)\n",
    "        df = df.sort_values(['container', 'timestamp']).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"‚úÖ {len(df)} registros coletados para {df['container'].nunique()} containers\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def parse_time_range(time_range):\n",
    "    \"\"\"Converte time_range para segundos\"\"\"\n",
    "    match = re.match(r'(\\d+)([smhd])', time_range.lower())\n",
    "    if not match:\n",
    "        raise ValueError(f\"Formato inv√°lido: {time_range}\")\n",
    "    \n",
    "    value = int(match.group(1))\n",
    "    unit = match.group(2)\n",
    "    \n",
    "    multipliers = {'s': 1, 'm': 60, 'h': 3600, 'd': 86400}\n",
    "    return value * multipliers[unit]\n",
    "\n",
    "def create_memory_time_chart(df, pod_name, save_file=True):\n",
    "    \"\"\"\n",
    "    Cria gr√°fico de tempo vs mem√≥ria\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        print(\"‚ùå Sem dados para gerar gr√°fico\")\n",
    "        return None\n",
    "    \n",
    "    # Configurar estilo\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "    sns.set_palette(\"husl\")\n",
    "    \n",
    "    # Criar figura\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    \n",
    "    # Agrupar por container\n",
    "    containers = df['container'].unique()\n",
    "    colors = plt.cm.Set3(range(len(containers)))\n",
    "    \n",
    "    for i, container in enumerate(containers):\n",
    "        container_data = df[df['container'] == container].copy()\n",
    "        container_data = container_data.sort_values('datetime')\n",
    "        \n",
    "        # Plotar linha\n",
    "        ax.plot(container_data['datetime'], \n",
    "                container_data['memory_mb'],\n",
    "                label=f'{container}',\n",
    "                linewidth=2,\n",
    "                marker='o',\n",
    "                markersize=3,\n",
    "                color=colors[i],\n",
    "                alpha=0.8)\n",
    "        \n",
    "        # Adicionar √°rea sombreada\n",
    "        ax.fill_between(container_data['datetime'], \n",
    "                       container_data['memory_mb'],\n",
    "                       alpha=0.2,\n",
    "                       color=colors[i])\n",
    "    \n",
    "    # Configurar eixos\n",
    "    ax.set_xlabel('Tempo (UTC)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Mem√≥ria (MB)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'Uso de Mem√≥ria ao Longo do Tempo\\nPod: {pod_name}', \n",
    "                fontsize=14, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Formata√ß√£o do eixo X (tempo)\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    ax.xaxis.set_major_locator(mdates.MinuteLocator(interval=5))\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Formata√ß√£o do eixo Y (mem√≥ria)\n",
    "    def format_mb(x, p):\n",
    "        if x >= 1000:\n",
    "            return f'{x/1000:.1f}GB'\n",
    "        return f'{x:.0f}MB'\n",
    "    \n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(format_mb))\n",
    "    \n",
    "    # Grid\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Legenda\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "    \n",
    "    # Estat√≠sticas no gr√°fico\n",
    "    stats_text = f\"\"\"Estat√≠sticas Gerais:\n",
    "‚Ä¢ M√≠n: {df['memory_mb'].min():.1f} MB\n",
    "‚Ä¢ M√°x: {df['memory_mb'].max():.1f} MB  \n",
    "‚Ä¢ M√©dia: {df['memory_mb'].mean():.1f} MB\n",
    "‚Ä¢ Per√≠odo: {df['datetime'].min().strftime('%H:%M')} - {df['datetime'].max().strftime('%H:%M')}\"\"\"\n",
    "    \n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, \n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', \n",
    "            facecolor='white', alpha=0.8), fontsize=9)\n",
    "    \n",
    "    # Ajustar layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salvar arquivo\n",
    "    if save_file:\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f'postgres_memory_chart_{timestamp}.png'\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        print(f\"üìä Gr√°fico salvo como: {filename}\")\n",
    "    \n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "def create_multiple_charts(df, pod_name):\n",
    "    \"\"\"\n",
    "    Cria m√∫ltiplos tipos de gr√°ficos\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    # 1. Gr√°fico de linha principal\n",
    "    print(\"üìä Criando gr√°fico de linha...\")\n",
    "    create_memory_time_chart(df, pod_name, save_file=True)\n",
    "    \n",
    "    # 2. Gr√°fico por container (subplots)\n",
    "    if df['container'].nunique() > 1:\n",
    "        print(\"ÔøΩÔøΩ Criando gr√°ficos separados por container...\")\n",
    "        \n",
    "        containers = df['container'].unique()\n",
    "        fig, axes = plt.subplots(len(containers), 1, figsize=(15, 4*len(containers)))\n",
    "        \n",
    "        if len(containers) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for i, container in enumerate(containers):\n",
    "            container_data = df[df['container'] == container].copy()\n",
    "            container_data = container_data.sort_values('datetime')\n",
    "            \n",
    "            axes[i].plot(container_data['datetime'], \n",
    "                        container_data['memory_mb'],\n",
    "                        linewidth=2, marker='o', markersize=2)\n",
    "            \n",
    "            axes[i].fill_between(container_data['datetime'], \n",
    "                               container_data['memory_mb'], alpha=0.3)\n",
    "            \n",
    "            axes[i].set_title(f'Container: {container}', fontweight='bold')\n",
    "            axes[i].set_ylabel('Mem√≥ria (MB)')\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "            axes[i].xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "            \n",
    "            # Estat√≠sticas por container\n",
    "            stats = f\"Min: {container_data['memory_mb'].min():.1f}MB | Max: {container_data['memory_mb'].max():.1f}MB | M√©dia: {container_data['memory_mb'].mean():.1f}MB\"\n",
    "            axes[i].text(0.02, 0.95, stats, transform=axes[i].transAxes, \n",
    "                        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7),\n",
    "                        fontsize=8)\n",
    "        \n",
    "        plt.xlabel('Tempo (UTC)')\n",
    "        plt.suptitle(f'Uso de Mem√≥ria por Container - Pod: {pod_name}', \n",
    "                    fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        filename = f'postgres_memory_by_container_{timestamp}.png'\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        print(f\"üìä Gr√°fico por container salvo: {filename}\")\n",
    "        plt.show()\n",
    "    \n",
    "    # 3. Histograma de distribui√ß√£o de mem√≥ria\n",
    "    print(\"üìä Criando histograma de distribui√ß√£o...\")\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    containers = df['container'].unique()\n",
    "    colors = plt.cm.Set3(range(len(containers)))\n",
    "    \n",
    "    for i, container in enumerate(containers):\n",
    "        container_data = df[df['container'] == container]\n",
    "        plt.hist(container_data['memory_mb'], bins=30, alpha=0.7, \n",
    "                label=container, color=colors[i], edgecolor='black')\n",
    "    \n",
    "    plt.xlabel('Mem√≥ria (MB)', fontweight='bold')\n",
    "    plt.ylabel('Frequ√™ncia', fontweight='bold')\n",
    "    plt.title(f'Distribui√ß√£o do Uso de Mem√≥ria - Pod: {pod_name}', \n",
    "              fontweight='bold', pad=20)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    filename = f'postgres_memory_distribution_{timestamp}.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"üìä Histograma salvo: {filename}\")\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    # Configura√ß√µes\n",
    "    PROMETHEUS_URL = \"http://192.168.242.131:9090\"\n",
    "    POD_NAME = \"postgres\"  # Ajuste conforme necess√°rio\n",
    "    TIME_RANGE = \"130m\"     # Per√≠odo de consulta\n",
    "    \n",
    "    print(\"üöÄ Gerando Gr√°ficos de Mem√≥ria vs Tempo\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Consultar dados\n",
    "    df = query_prometheus_memory_for_chart(PROMETHEUS_URL, POD_NAME, TIME_RANGE)\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"‚ùå Sem dados para gerar gr√°ficos\")\n",
    "        return\n",
    "    \n",
    "    # Mostrar resumo dos dados\n",
    "    print(f\"\\nüìä Resumo dos dados coletados:\")\n",
    "    print(f\"   üìà Total de registros: {len(df)}\")\n",
    "    print(f\"   ‚è∞ Per√≠odo: {df['datetime'].min()} at√© {df['datetime'].max()}\")\n",
    "    print(f\"   üì¶ Containers: {', '.join(df['container'].unique())}\")\n",
    "    print(f\"   üñ•Ô∏è  Instances: {', '.join(df['instance'].unique())}\")\n",
    "    \n",
    "    # Criar gr√°ficos\n",
    "    print(f\"\\nüìä Gerando gr√°ficos...\")\n",
    "    create_multiple_charts(df, POD_NAME)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Gr√°ficos gerados com sucesso!\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Instalar depend√™ncias necess√°rias:\n",
    "    # pip install matplotlib seaborn requests pandas\n",
    "    \n",
    "    dataset = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
